{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "## P+7 (Oulipian language modelling)\n",
        "\n",
        "### Background\n",
        "\n",
        "The Oulipo (*Ouvroir de Littérature Potentielle*, or “Workshop of Potential Literature”) is a French literary group founded in 1960 by writer Raymond Queneau and mathematician François Le Lionnais. The group focuses on using rules and constraints in writing as a way to spark creativity. Rather than seeing constraints as obstacles, Oulipians treat them as tools to inspire new forms of storytelling and poetry. Their work combines mathematics, language, and playfulness, making their approach both unique and influential in modern literature.\n",
        "\n",
        "One of the most famous Oulipian writers is Georges Perec, who is known for his creative use of constraints. His novel *La Disparition* (“A Void”) is written entirely without the letter \"e,\" which is especially challenging given how common \"e\" is in French. Perec’s writing often plays with the structure of language in surprising ways. One popular Oulipian technique is N+7, where each noun in a text is replaced by the noun seven entries later in a dictionary. This creates unusual, absurd, and often funny results, encouraging writers to think differently about language and meaning.\n",
        "\n",
        "![George Perec](https://upload.wikimedia.org/wikipedia/commons/7/76/Myart_georges-perec_1978.jpg)\n",
        "\n",
        "(George Perec, 1978. From Wikidata)\n",
        "\n",
        "<!-- <img src=\"https://media.vigliensoni.com/clips/CART498/perec-01.jpg\" width=\"800\"> -->\n",
        "\n",
        "\n",
        "## How it works\n",
        "\n",
        "The N+7 technique process is straightforward\n",
        "\n",
        "- **Start with a text**. Choose any text—this could be a poem, a sentence, or a passage.\n",
        "- **Use a dictionary**. Have a dictionary (or word list) handy.\n",
        "- **Replace each noun**. For every substantive noun in the original text, replace it with the noun appearing seven nouns away in the dictionary. If the end of the dictionary is reached, you can loop back to the beginning.\n",
        "- **Maintain grammar**. Ensure the new text maintains grammatical correctness as much as possible, though the results often turn out  surreal and nonsensical.\n",
        "\n",
        "For example, using the N+7 technique with a standard English dictionary for the original sentence:\n",
        "\n",
        "*The cat sat on the mat*.\n",
        "\n",
        "- ”Cat” → 7 nouns after “cat” is “catalog.”\n",
        "- ”Mat” → 7 nouns after ”mat” is ”material.”\n",
        "\n",
        "Results in:\n",
        "\n",
        "*The catalog sat on the material.*\n",
        "\n",
        "### Assignment and deliverables\n",
        "\n",
        "For this assignment, you will create a variation of the N+7 technique we will name P+7. Using the GPT-2 language model, you will replace the last word of each line from *The Snow Man* with the word that has the seventh-highest probability according to the model’s predictions.\n",
        "\n",
        "By the end of this assignment, submit a link to a GitHub repository named `CART498-GenAI` containing a folder labelled `A02` with the following items:\n",
        "\n",
        "- A version of the text processed with your P+7 technique, saved as a `.txt` file.\n",
        "- A second version of the text processed with `P+x`. Choose an `x` value that produces the funniest, wittiest, or most absurd version of the original text. Save this as a .txt file, and include the `x` value in the filename (e.g., `P+23.txt` or `P+12.txt`).\n",
        "- A Python notebook with the script used to generate your P+7 and P+x transformations using the GPT-2 language model.\n",
        "- A short reflection (250–350 words) explaining how altering the `x` value impacted the output of your P+x version. Additionally, discuss how you would implement a P+7 technique in which all nouns are replaced with their seventh-highest probability alternatives.\n",
        "\n",
        "### *The Snow Man*\n",
        "by Wallace Stevens (1879-1955)\n",
        "\n",
        "\n",
        "> One must have a mind of winter  \n",
        "> To regard the frost and the boughs  \n",
        "> Of the pine-trees crusted with snow;  \n",
        "> And have been cold a long time  \n",
        "> To behold the junipers shagged with ice,  \n",
        "> The spruces rough in the distant glitter  \n",
        "> Of the January sun; and not to think  \n",
        "> Of any misery in the sound of the wind,  \n",
        "> In the sound of a few leaves,  \n",
        "> Which is the sound of the land  \n",
        "> Full of the same wind  \n",
        "> That is blowing in the same bare place  \n",
        "> For the listener, who listens in the snow,  \n",
        "> And, nothing himself, beholds  \n",
        "> Nothing that is not there and the nothing that is.  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lmvekj8ro3HC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: For this assignment, you will create a variation of the N+7 technique we will name P+7. Using the GPT-2 language model, you will replace the last word of each line from The Snow Man with the word that has the seventh-highest probability according to the model’s predictions.\n",
        "\n",
        "!pip install transformers\n",
        "\n",
        "from transformers import pipeline, GPT2TokenizerFast\n",
        "\n",
        "# Load the GPT-2 model and tokenizer\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
        "\n",
        "# The Snow Man poem\n",
        "poem = \"\"\"\n",
        "One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\n",
        "\"\"\"\n",
        "\n",
        "def p_plus_x(text, x):\n",
        "    lines = text.strip().split('\\n')\n",
        "    new_poem = \"\"\n",
        "    for line in lines:\n",
        "        words = line.split()\n",
        "        if words:\n",
        "          # Generate text with GPT-2\n",
        "          input_text = \" \".join(words[:-1])  # Input everything except the last word\n",
        "          result = generator(input_text, max_length=len(input_text) + 10, num_return_sequences=1)\n",
        "          generated_text = result[0]['generated_text']\n",
        "          generated_words = generated_text.split()\n",
        "\n",
        "          # Find the xth most probable word\n",
        "          try:\n",
        "              new_word = generated_words[len(words) - 1]\n",
        "          except IndexError:\n",
        "            new_word = \"[ERROR]\" # Handle cases where GPT-2 doesn't provide enough predictions\n",
        "\n",
        "\n",
        "          new_line = \" \".join(words[:-1]) + \" \" + new_word\n",
        "          new_poem += new_line + \"\\n\"\n",
        "        else:\n",
        "          new_poem += \"\\n\"\n",
        "\n",
        "    return new_poem\n",
        "\n",
        "\n",
        "# Create P+7 version\n",
        "p7_poem = p_plus_x(poem, 7)\n",
        "print(\"P+7 Version:\\n\", p7_poem)\n",
        "\n",
        "with open(\"P+7.txt\", \"w\") as f:\n",
        "    f.write(p7_poem)\n",
        "\n",
        "\n",
        "# Example with P+12 (you can change the value of x as desired)\n",
        "p12_poem = p_plus_x(poem, 12)\n",
        "\n",
        "with open(\"P+12.txt\", \"w\") as f:\n",
        "    f.write(p12_poem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYGX3FWTDdK_",
        "outputId": "43b9c867-09be-427e-aa73-28462f1aa221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P+7 Version:\n",
            " One must have a mind of their\n",
            "To regard the frost and the rain\n",
            "Of the pine-trees crusted with the\n",
            "And have been cold a long time,\n",
            "To behold the junipers shagged with the\n",
            "The spruces rough in the distant distance.\n",
            "Of the January sun; and not to think\n",
            "Of any misery in the sound of the drum,\n",
            "In the sound of a few loud\n",
            "Which is the sound of the sound?\n",
            "Full of the same in\n",
            "That is blowing in the same bare and\n",
            "For the listener, who listens in the same\n",
            "And, nothing himself, except\n",
            "Nothing that is not there and the nothing that is\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: For this assignment, you will create a variation of the N+7 technique we will name P+x. Using the GPT-2 language model, you will replace the last word of each line from The Snow Man with the word that has the seventh-highest probability according to the model’s predictions. Choose an x value that produces the funniest, wittiest, or most absurd version of the original text.\n",
        "\n",
        "# Example with P+23 (you can change the value of x as desired)\n",
        "p23_poem = p_plus_x(poem, 23)\n",
        "\n",
        "with open(\"P+23.txt\", \"w\") as f:\n",
        "    f.write(p23_poem)\n",
        "\n",
        "print(\"P+23 Version:\\n\", p23_poem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-zo1uFWHUNG",
        "outputId": "317328ab-802a-4554-8154-c2f6e5150347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P+23 Version:\n",
            " One must have a mind of his\n",
            "To regard the frost and the great\n",
            "Of the pine-trees crusted with the\n",
            "And have been cold a long while\n",
            "To behold the junipers shagged with their\n",
            "The spruces rough in the distant south,\n",
            "Of the January sun; and not to be\n",
            "Of any misery in the sound of the voices,\n",
            "In the sound of a few small\n",
            "Which is the sound of the fire\n",
            "Full of the same And\n",
            "That is blowing in the same bare wind.\n",
            "For the listener, who listens in the current\n",
            "And, nothing himself, everything\n",
            "Nothing that is not there and the nothing that exists\n",
            "\n"
          ]
        }
      ]
    }
  ]
}